{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of VGG16 network in Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'test/_weights:0' shape=(3, 3, 1, 32) dtype=float32_ref>\n",
      "<tf.Variable 'fc/_weights:0' shape=(784, 32) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "###############################################\n",
    "## Author: Vahid Mirjalili                   ##\n",
    "## Dept. of Computer Science & Engineering   ##\n",
    "## Michigan State University                 ##\n",
    "###############################################\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "#######################\n",
    "## Wrapper Functions ##\n",
    "#######################\n",
    "\n",
    "def conv_layer(input_tensor, name,\n",
    "               kernel_size=(3,3), n_filters=256, \n",
    "               padding_mode='SAME', strides=(1,1,1,1)):\n",
    "    with tf.variable_scope(name):\n",
    "        ## get n_input_channels:\n",
    "        ##   input tensor shape: [batch x width x height x channels_in]\n",
    "        n_input_channels = input_tensor.get_shape().as_list()[-1] \n",
    "\n",
    "        weights_shape = list(kernel_size) + \\\n",
    "                        [n_input_channels, n_filters]\n",
    "\n",
    "        weights_init = tf.contrib.layers.xavier_initializer_conv2d()\n",
    "        weights = tf.get_variable(name='_weights',\n",
    "                                  shape=weights_shape,\n",
    "                                  initializer=weights_init)\n",
    "        biases = tf.get_variable(name='_biases',\n",
    "                                 initializer=tf.zeros(shape=[n_filters]))\n",
    "        conv = tf.nn.conv2d(input=input_tensor, filter=weights,\n",
    "                            strides=strides, padding=padding_mode)\n",
    "        conv = tf.nn.bias_add(conv, biases)\n",
    "        conv = tf.nn.relu(conv)\n",
    "        print(weights)\n",
    "        \n",
    "        return conv\n",
    "\n",
    "## testing    \n",
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(tf.float32, shape=[None,28,28,1])\n",
    "conv_layer(x, name='test', kernel_size=(3,3), n_filters=32)\n",
    "\n",
    "def pool_layer(input_tensor, name):\n",
    "    return tf.nn.max_pool(input_tensor, \n",
    "                          ksize=[1, 2, 2, 1],\n",
    "                          strides=[1, 2, 2, 1], \n",
    "                          padding='SAME', \n",
    "                          name=name)\n",
    "\n",
    "def fc_layer(input_tensor, name, \n",
    "             n_output_units, dropout=None, \n",
    "             activation_fn=None):\n",
    "    with tf.variable_scope(name):\n",
    "        input_shape = input_tensor.get_shape().as_list()[1:]\n",
    "        n_input_units = np.prod(input_shape)\n",
    "        if len(input_shape) > 1:\n",
    "            input_tensor = tf.reshape(input_tensor, \n",
    "                                      shape=(-1, n_input_units))\n",
    "        if dropout is not None:\n",
    "            input_tensor = tf.nn.dropout(input_tensor, keep_prob=dropout)\n",
    "\n",
    "        weights_shape = [n_input_units, n_output_units]\n",
    "        weights_init = tf.contrib.layers.xavier_initializer()\n",
    "        weights = tf.get_variable(name='_weights',\n",
    "                                  shape=weights_shape,\n",
    "                                  initializer=weights_init)\n",
    "        biases = tf.get_variable(name='_biases',\n",
    "                                 initializer=tf.zeros(shape=[n_output_units]))\n",
    "        layer = tf.matmul(input_tensor, weights)\n",
    "        layer = tf.nn.bias_add(layer, biases)\n",
    "        print(weights)\n",
    "        if activation_fn is None:\n",
    "            return layer\n",
    "        layer = activation_fn(layer)\n",
    "        return layer\n",
    "    \n",
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(tf.float32, shape=[None,28,28,1])\n",
    "fc_layer(x, name='fc', n_output_units=32, activation_fn=tf.nn.relu)\n",
    "\n",
    "#############################\n",
    "###      VGG16 Class      ###\n",
    "#############################\n",
    "\n",
    "class VGG16(object):\n",
    "    def __init__(self, n_features, n_classes,\n",
    "                 epochs=40, learning_rate=1e-5, dropout=0.5,\n",
    "                 shuffle=True, random_state = None, weight_file=None, \n",
    "                 initialize=False):\n",
    "        np.random.seed(random_state)\n",
    "        self.n_features = n_features  # a tuple\n",
    "        self.n_classes = n_classes\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.dropout = dropout\n",
    "       \n",
    "        g = tf.Graph() \n",
    "        with g.as_default():\n",
    "            ## build the network\n",
    "            self.build()\n",
    "            self.saver = tf.train.Saver()\n",
    "\n",
    "            ## create a session:\n",
    "            self.sess = tf.Session(graph=g)\n",
    "\n",
    "            if weight_file is not None:\n",
    "                self.load_params(weight_file)\n",
    "            elif initialize:\n",
    "                ##initialize variables\n",
    "                try:\n",
    "                    self.sess.run(tf.global_variables_initializer())\n",
    "                except:\n",
    "                    self.sess.run(tf.initialize_all_variables())\n",
    "\n",
    "    def save(self, path):\n",
    "        self.saver.save(self.sess, path)\n",
    "\n",
    "    def load(self, path):\n",
    "        self.saver.restore(self.sess, path)\n",
    " \n",
    "    def build(self):\n",
    "        \n",
    "        self.tf_x = tf.placeholder(tf.float32, \n",
    "                                   shape=[None, \n",
    "                                          self.n_features[0], \n",
    "                                          self.n_features[1], \n",
    "                                          self.n_features[2]],\n",
    "                                   name='inputs')\n",
    "        self.tf_y = tf.placeholder(tf.int32, shape=[None], \n",
    "                                   name='targets')\n",
    "        tf_y_onehot = tf.one_hot(self.tf_y, depth=self.n_classes)\n",
    "        print(' ** x : ', self.tf_x)\n",
    "        print(' ** y_ : ', self.tf_y)\n",
    "        print(' ** y1hot: ', tf_y_onehot)\n",
    "\n",
    "        ### Convolutional Layers ###\n",
    "        h_conv1_1 = conv_layer(self.tf_x, name='conv1_1', n_filters=64)\n",
    "        h_conv1_2 = conv_layer(h_conv1_1, name='conv1_2', n_filters=64)\n",
    "        h_pool1   = pool_layer(h_conv1_2, name='pool1')\n",
    "\n",
    "        h_conv2_1 = conv_layer(h_pool1,   name='conv2_1', n_filters=128)\n",
    "        h_conv2_2 = conv_layer(h_conv2_1, name='conv2_2', n_filters=128)\n",
    "        h_pool2   = pool_layer(h_conv2_2, name='pool2')\n",
    "\n",
    "        h_conv3_1 = conv_layer(h_pool2,   name='conv3_1', n_filters=256)\n",
    "        h_conv3_2 = conv_layer(h_conv3_1, name='conv3_2', n_filters=256)\n",
    "        h_conv3_3 = conv_layer(h_conv3_2, name='conv3_3', n_filters=256)\n",
    "        h_pool3   = pool_layer(h_conv3_3, name='pool3')\n",
    "\n",
    "        h_conv4_1 = conv_layer(h_pool3,   name='conv4_1', n_filters=512)\n",
    "        h_conv4_2 = conv_layer(h_conv4_1, name='conv4_2', n_filters=512)\n",
    "        h_conv4_3 = conv_layer(h_conv4_2, name='conv4_3', n_filters=512)\n",
    "        h_pool4   = pool_layer(h_conv4_3, name='pool4')\n",
    "\n",
    "        h_conv5_1 = conv_layer(h_pool4,   name='conv5_1', n_filters=512)\n",
    "        h_conv5_2 = conv_layer(h_conv5_1, name='conv5_2', n_filters=512)\n",
    "        h_conv5_3 = conv_layer(h_conv5_2, name='conv5_3', n_filters=512)\n",
    "        h_pool5   = pool_layer(h_conv5_3, name='pool5')\n",
    "\n",
    "\n",
    "        ## 1st FC Layer\n",
    "        self.keep_prob_fc1 = tf.placeholder(tf.float32, name='keep_prob_fc1')\n",
    "        print(self.keep_prob_fc1)\n",
    "        h_fc1 = fc_layer(h_pool5, name='fc1', \n",
    "                         n_output_units=1024,  ## original: 4096\n",
    "                         dropout=self.keep_prob_fc1,\n",
    "                         activation_fn=tf.nn.relu)\n",
    "        ## 2nd FC Layer\n",
    "        self.keep_prob_fc2 = tf.placeholder(tf.float32, name='keep_prob_fc2')\n",
    "        print(self.keep_prob_fc2)\n",
    "        h_fc2 = fc_layer(h_fc1, name='fc2', \n",
    "                         n_output_units=1024, ## original: 4096\n",
    "                         dropout=self.keep_prob_fc2,\n",
    "                         activation_fn=tf.nn.relu)\n",
    "        ## 3rd FC Layer\n",
    "        logits = fc_layer(h_fc2, name='fc3', \n",
    "                         n_output_units=self.n_classes, \n",
    "                         dropout=None, activation_fn=None)\n",
    "\n",
    "        self.predictions = {\n",
    "            'labels' : tf.cast(tf.argmax(logits, 1), tf.int32),\n",
    "            'probabilities' : tf.nn.softmax(logits)\n",
    "        }\n",
    "        \n",
    "        ## Loss Function and Optimization\n",
    "        self.cross_entropy = tf.reduce_mean(\n",
    "                               tf.nn.softmax_cross_entropy_with_logits(\n",
    "                                   logits = logits, \n",
    "                                   labels = tf_y_onehot),\n",
    "                               name='cross_entropy_loss')\n",
    "        optimizer = tf.train.AdamOptimizer(self.learning_rate, name='adam_ptimizer')\n",
    "        self.optimizer = optimizer.minimize(self.cross_entropy, name='optimizer_minimize_loss')\n",
    "        \n",
    "        ## Finding accuracy\n",
    "        correct_prediction = tf.equal(self.predictions['labels'], \n",
    "                                      self.tf_y)\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "        \n",
    "    def train_batch(self, batch_x, batch_y):\n",
    "        \n",
    "        _, loss = self.sess.run([self.optimizer, self.cross_entropy], \n",
    "                                feed_dict={self.tf_x :batch_x, \n",
    "                                           self.tf_y: batch_y, \n",
    "                                           self.keep_prob_fc1: self.dropout,\n",
    "                                           self.keep_prob_fc2: self.dropout})\n",
    "        return loss\n",
    "                    \n",
    "    def predict(self, X, return_proba=False):\n",
    "        predictions = self.sess.run(self.predictions, \n",
    "                                    feed_dict={self.tf_x:X, \n",
    "                                               self.keep_prob_fc1: 1.0, \n",
    "                                               self.keep_prob_fc2:1.0})\n",
    "        if return_proba:\n",
    "            return predictions['probabilities']\n",
    "        else:\n",
    "            return predictions['labels']\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
